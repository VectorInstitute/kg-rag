{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41d980ceb0af46fbb05dad061ad2d380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7aa60185e554956895355ce7f872096",
              "IPY_MODEL_8dbeee2a1bf54f6f88a29655de4e5d3a",
              "IPY_MODEL_f2acb18b9278454885ab1a04d59504a7"
            ],
            "layout": "IPY_MODEL_ef70d5964d9f4d27aeebc1ab78606581"
          }
        },
        "f7aa60185e554956895355ce7f872096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1778cef7edbe46819ef5e2fd89aac7a5",
            "placeholder": "​",
            "style": "IPY_MODEL_41fa5f5c63ed45f48f06952db7234fec",
            "value": "Map: 100%"
          }
        },
        "8dbeee2a1bf54f6f88a29655de4e5d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee0ac9b01a844ef880a2c0ba1ce57c5",
            "max": 627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfcfc120792341df9c59f47976dd8549",
            "value": 627
          }
        },
        "f2acb18b9278454885ab1a04d59504a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_534e6e7b81a04d558cff20028bc86812",
            "placeholder": "​",
            "style": "IPY_MODEL_e12227e9feab4a518c61f0abc292d02e",
            "value": " 627/627 [00:00&lt;00:00, 4321.98 examples/s]"
          }
        },
        "ef70d5964d9f4d27aeebc1ab78606581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1778cef7edbe46819ef5e2fd89aac7a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41fa5f5c63ed45f48f06952db7234fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ee0ac9b01a844ef880a2c0ba1ce57c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfcfc120792341df9c59f47976dd8549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "534e6e7b81a04d558cff20028bc86812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12227e9feab4a518c61f0abc292d02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06eac2f904145b78b093d5a3e489030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64b235ff255346f7a6608016d03fcefc",
              "IPY_MODEL_059c7ab03a6e4a889b5208a632af85c3",
              "IPY_MODEL_85e15b6fa0a44954957bf4126936bc56"
            ],
            "layout": "IPY_MODEL_bf4e754bcc6d4422bc2184203d3de6b1"
          }
        },
        "64b235ff255346f7a6608016d03fcefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23becbea9b3d4a8188789a3fb3abda8e",
            "placeholder": "​",
            "style": "IPY_MODEL_ad4ce66e11124b6bad3a666b7927b170",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "059c7ab03a6e4a889b5208a632af85c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_016bf3cda55f4429a928d16c949176c3",
            "max": 627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bad0246fcfe248baa57fbc3d358df08b",
            "value": 627
          }
        },
        "85e15b6fa0a44954957bf4126936bc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41837ed3a4e34995a576bd174aaec877",
            "placeholder": "​",
            "style": "IPY_MODEL_3be8358daaaf49458281199d2bdcbc7c",
            "value": " 627/627 [00:08&lt;00:00, 89.32 examples/s]"
          }
        },
        "bf4e754bcc6d4422bc2184203d3de6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23becbea9b3d4a8188789a3fb3abda8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4ce66e11124b6bad3a666b7927b170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "016bf3cda55f4429a928d16c949176c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad0246fcfe248baa57fbc3d358df08b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41837ed3a4e34995a576bd174aaec877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be8358daaaf49458281199d2bdcbc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaaede9f154343f6b8ea518918ac6ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d86d8f9b25914770bf1064c5bf9bb375",
              "IPY_MODEL_157f388119e24237bc5aca555c94d656",
              "IPY_MODEL_de19ee818f6e4edfa4538bcd363c84c6"
            ],
            "layout": "IPY_MODEL_b510619679904ebabde226b705f092de"
          }
        },
        "d86d8f9b25914770bf1064c5bf9bb375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd7e54da10f4342807cde0e84b1183c",
            "placeholder": "​",
            "style": "IPY_MODEL_fedf8959c41f41b89cc95bb2356e2d34",
            "value": "Map: 100%"
          }
        },
        "157f388119e24237bc5aca555c94d656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b66895e7274d78b3d0875cc793a8df",
            "max": 627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_883443f49be94fcba5b6198d54e64633",
            "value": 627
          }
        },
        "de19ee818f6e4edfa4538bcd363c84c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c795a1a5eb7f4914a97b9bedfe1e79eb",
            "placeholder": "​",
            "style": "IPY_MODEL_6e7a3883517b49f88d35248d372fb7aa",
            "value": " 627/627 [00:00&lt;00:00, 1539.96 examples/s]"
          }
        },
        "b510619679904ebabde226b705f092de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd7e54da10f4342807cde0e84b1183c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedf8959c41f41b89cc95bb2356e2d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0b66895e7274d78b3d0875cc793a8df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883443f49be94fcba5b6198d54e64633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c795a1a5eb7f4914a97b9bedfe1e79eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7a3883517b49f88d35248d372fb7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Efficient Fine-Tuning of Large Language Models\n",
        "\n",
        "Fine-tuning large language models (LLMs) is a critical process that allows these models to adapt to specific tasks or domains. While traditional fine-tuning methods often require significant computational resources, recent advancements in parameter-efficient techniques have made this process more accessible.\n",
        "\n",
        "#### Parameter-Efficient Fine-Tuning Techniques\n",
        "\n",
        "1. **Low-Rank Adaptation (LoRA):**  \n",
        "   LoRA introduces trainable low-rank matrices into each layer of a pre-trained model, enabling task-specific adaptation with minimal additional parameters ([Hu et al., 2021](https://arxiv.org/abs/2106.09685)).\n",
        "\n",
        "2. **Prefix Tuning:**  \n",
        "   This approach adds task-specific prefixes to condition the model’s attention mechanisms, fine-tuning only a small fraction of parameters ([Li & Liang, 2021](https://arxiv.org/abs/2101.00190)).\n",
        "\n",
        "3. **Adapter Modules:**  \n",
        "   Adapter layers are inserted into the model architecture and trained for specific tasks while the core model remains unchanged, reducing computational overhead ([Houlsby et al., 2019](https://arxiv.org/abs/1902.00751)).\n",
        "\n",
        "These techniques are designed to reduce the computational and memory demands of fine-tuning, making it feasible on smaller hardware setups.\n",
        "\n",
        "---\n",
        "\n",
        "#### Efficient Fine-Tuning Frameworks\n",
        "\n",
        "Several tools and frameworks have been developed to facilitate efficient fine-tuning, integrating methods such as quantization, optimized backpropagation, and low-memory usage.\n",
        "Unsloth is one such framework that incorporates advanced optimization techniques for efficient fine-tuning. It supports features such as 4-bit quantization to minimize memory usage, optimized training kernels for speed, and compatibility with diverse models like Llama-3 and Mistral ([Unsloth Documentation](https://docs.unsloth.ai/)).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### References\n",
        "\n",
        "1. Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., & Chen, W. (2021). LoRA: Low-Rank Adaptation of Large Language Models. *arXiv preprint arXiv:2106.09685*.  \n",
        "2. Li, X. L., & Liang, P. (2021). Prefix-Tuning: Optimizing Continuous Prompts for Generation. *arXiv preprint arXiv:2101.00190*.  \n",
        "3. Houlsby, N., Giurgiu, A., Jastrzębski, S., Morrone, B., & Gelly, S. (2019). Parameter-efficient transfer learning for NLP. *arXiv preprint arXiv:1902.00751*.  \n",
        "4. Unsloth Documentation: [https://docs.unsloth.ai/](https://docs.unsloth.ai/)\n",
        "\n",
        "---\n",
        "\n",
        "#### About This Tutorial\n",
        "\n",
        "In this tutorial, we will explore the principles of efficient fine-tuning, demonstrate how frameworks like Unsloth implement these principles, and provide hands-on examples to apply these techniques in real-world scenarios. By the end, you will have a clear understanding of how to fine-tune LLMs efficiently for your specific tasks.\n"
      ],
      "metadata": {
        "id": "WCuxRaNCUyo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Open Your Google Drive and Colab\n",
        "\n",
        "1. **Google Drive**: Go to [Google Drive](https://drive.google.com) and log in with your account.\n",
        "2. **Google Colab**: Open [Google Colab](https://colab.research.google.com) to run and edit Python notebooks in the cloud.\n",
        "3. **Runtime Setup**: In Colab, go to `Runtime` > `Change runtime type` and select **GPU (T4)** under the hardware accelerator options for efficient computation.\n"
      ],
      "metadata": {
        "id": "T1yTPIFwUOt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Installing Required Dependencies for Unsloth\n",
        "\n",
        "This script installs and upgrades the necessary libraries to work with the **Unsloth** framework effectively.\n",
        "\n",
        "#### Code Explanation:\n",
        "\n",
        "1. **`%%capture`**:\n",
        "   - Suppresses the output of the following commands to maintain a cleaner notebook environment.\n",
        "\n",
        "2. **Installing Required Libraries**:\n",
        "   ```bash\n",
        "   !pip install unsloth \"xformers==0.0.28.post2\" codecarbon google transformers\n"
      ],
      "metadata": {
        "id": "EYtDKcafWgK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ],
      "metadata": {
        "id": "ReowaYppU_-8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check installation\n",
        "!pip show unsloth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjyXIukHWyhJ",
        "outputId": "3e467b03-99dc-40f1-a07d-d567dfa89ae9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: unsloth\n",
            "Version: 2024.12.2\n",
            "Summary: 2-5X faster LLM finetuning\n",
            "Home-page: http://www.unsloth.ai\n",
            "Author: Unsloth AI team\n",
            "Author-email: info@unsloth.ai\n",
            "License: Apache License\n",
            "                                   Version 2.0, January 2004\n",
            "                                http://www.apache.org/licenses/\n",
            "        \n",
            "           TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
            "        \n",
            "           1. Definitions.\n",
            "        \n",
            "              \"License\" shall mean the terms and conditions for use, reproduction,\n",
            "              and distribution as defined by Sections 1 through 9 of this document.\n",
            "        \n",
            "              \"Licensor\" shall mean the copyright owner or entity authorized by\n",
            "              the copyright owner that is granting the License.\n",
            "        \n",
            "              \"Legal Entity\" shall mean the union of the acting entity and all\n",
            "              other entities that control, are controlled by, or are under common\n",
            "              control with that entity. For the purposes of this definition,\n",
            "              \"control\" means (i) the power, direct or indirect, to cause the\n",
            "              direction or management of such entity, whether by contract or\n",
            "              otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
            "              outstanding shares, or (iii) beneficial ownership of such entity.\n",
            "        \n",
            "              \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
            "              exercising permissions granted by this License.\n",
            "        \n",
            "              \"Source\" form shall mean the preferred form for making modifications,\n",
            "              including but not limited to software source code, documentation\n",
            "              source, and configuration files.\n",
            "        \n",
            "              \"Object\" form shall mean any form resulting from mechanical\n",
            "              transformation or translation of a Source form, including but\n",
            "              not limited to compiled object code, generated documentation,\n",
            "              and conversions to other media types.\n",
            "        \n",
            "              \"Work\" shall mean the work of authorship, whether in Source or\n",
            "              Object form, made available under the License, as indicated by a\n",
            "              copyright notice that is included in or attached to the work\n",
            "              (an example is provided in the Appendix below).\n",
            "        \n",
            "              \"Derivative Works\" shall mean any work, whether in Source or Object\n",
            "              form, that is based on (or derived from) the Work and for which the\n",
            "              editorial revisions, annotations, elaborations, or other modifications\n",
            "              represent, as a whole, an original work of authorship. For the purposes\n",
            "              of this License, Derivative Works shall not include works that remain\n",
            "              separable from, or merely link (or bind by name) to the interfaces of,\n",
            "              the Work and Derivative Works thereof.\n",
            "        \n",
            "              \"Contribution\" shall mean any work of authorship, including\n",
            "              the original version of the Work and any modifications or additions\n",
            "              to that Work or Derivative Works thereof, that is intentionally\n",
            "              submitted to Licensor for inclusion in the Work by the copyright owner\n",
            "              or by an individual or Legal Entity authorized to submit on behalf of\n",
            "              the copyright owner. For the purposes of this definition, \"submitted\"\n",
            "              means any form of electronic, verbal, or written communication sent\n",
            "              to the Licensor or its representatives, including but not limited to\n",
            "              communication on electronic mailing lists, source code control systems,\n",
            "              and issue tracking systems that are managed by, or on behalf of, the\n",
            "              Licensor for the purpose of discussing and improving the Work, but\n",
            "              excluding communication that is conspicuously marked or otherwise\n",
            "              designated in writing by the copyright owner as \"Not a Contribution.\"\n",
            "        \n",
            "              \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
            "              on behalf of whom a Contribution has been received by Licensor and\n",
            "              subsequently incorporated within the Work.\n",
            "        \n",
            "           2. Grant of Copyright License. Subject to the terms and conditions of\n",
            "              this License, each Contributor hereby grants to You a perpetual,\n",
            "              worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
            "              copyright license to reproduce, prepare Derivative Works of,\n",
            "              publicly display, publicly perform, sublicense, and distribute the\n",
            "              Work and such Derivative Works in Source or Object form.\n",
            "        \n",
            "           3. Grant of Patent License. Subject to the terms and conditions of\n",
            "              this License, each Contributor hereby grants to You a perpetual,\n",
            "              worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
            "              (except as stated in this section) patent license to make, have made,\n",
            "              use, offer to sell, sell, import, and otherwise transfer the Work,\n",
            "              where such license applies only to those patent claims licensable\n",
            "              by such Contributor that are necessarily infringed by their\n",
            "              Contribution(s) alone or by combination of their Contribution(s)\n",
            "              with the Work to which such Contribution(s) was submitted. If You\n",
            "              institute patent litigation against any entity (including a\n",
            "              cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
            "              or a Contribution incorporated within the Work constitutes direct\n",
            "              or contributory patent infringement, then any patent licenses\n",
            "              granted to You under this License for that Work shall terminate\n",
            "              as of the date such litigation is filed.\n",
            "        \n",
            "           4. Redistribution. You may reproduce and distribute copies of the\n",
            "              Work or Derivative Works thereof in any medium, with or without\n",
            "              modifications, and in Source or Object form, provided that You\n",
            "              meet the following conditions:\n",
            "        \n",
            "              (a) You must give any other recipients of the Work or\n",
            "                  Derivative Works a copy of this License; and\n",
            "        \n",
            "              (b) You must cause any modified files to carry prominent notices\n",
            "                  stating that You changed the files; and\n",
            "        \n",
            "              (c) You must retain, in the Source form of any Derivative Works\n",
            "                  that You distribute, all copyright, patent, trademark, and\n",
            "                  attribution notices from the Source form of the Work,\n",
            "                  excluding those notices that do not pertain to any part of\n",
            "                  the Derivative Works; and\n",
            "        \n",
            "              (d) If the Work includes a \"NOTICE\" text file as part of its\n",
            "                  distribution, then any Derivative Works that You distribute must\n",
            "                  include a readable copy of the attribution notices contained\n",
            "                  within such NOTICE file, excluding those notices that do not\n",
            "                  pertain to any part of the Derivative Works, in at least one\n",
            "                  of the following places: within a NOTICE text file distributed\n",
            "                  as part of the Derivative Works; within the Source form or\n",
            "                  documentation, if provided along with the Derivative Works; or,\n",
            "                  within a display generated by the Derivative Works, if and\n",
            "                  wherever such third-party notices normally appear. The contents\n",
            "                  of the NOTICE file are for informational purposes only and\n",
            "                  do not modify the License. You may add Your own attribution\n",
            "                  notices within Derivative Works that You distribute, alongside\n",
            "                  or as an addendum to the NOTICE text from the Work, provided\n",
            "                  that such additional attribution notices cannot be construed\n",
            "                  as modifying the License.\n",
            "        \n",
            "              You may add Your own copyright statement to Your modifications and\n",
            "              may provide additional or different license terms and conditions\n",
            "              for use, reproduction, or distribution of Your modifications, or\n",
            "              for any such Derivative Works as a whole, provided Your use,\n",
            "              reproduction, and distribution of the Work otherwise complies with\n",
            "              the conditions stated in this License.\n",
            "        \n",
            "           5. Submission of Contributions. Unless You explicitly state otherwise,\n",
            "              any Contribution intentionally submitted for inclusion in the Work\n",
            "              by You to the Licensor shall be under the terms and conditions of\n",
            "              this License, without any additional terms or conditions.\n",
            "              Notwithstanding the above, nothing herein shall supersede or modify\n",
            "              the terms of any separate license agreement you may have executed\n",
            "              with Licensor regarding such Contributions.\n",
            "        \n",
            "           6. Trademarks. This License does not grant permission to use the trade\n",
            "              names, trademarks, service marks, or product names of the Licensor,\n",
            "              except as required for reasonable and customary use in describing the\n",
            "              origin of the Work and reproducing the content of the NOTICE file.\n",
            "        \n",
            "           7. Disclaimer of Warranty. Unless required by applicable law or\n",
            "              agreed to in writing, Licensor provides the Work (and each\n",
            "              Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
            "              WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
            "              implied, including, without limitation, any warranties or conditions\n",
            "              of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
            "              PARTICULAR PURPOSE. You are solely responsible for determining the\n",
            "              appropriateness of using or redistributing the Work and assume any\n",
            "              risks associated with Your exercise of permissions under this License.\n",
            "        \n",
            "           8. Limitation of Liability. In no event and under no legal theory,\n",
            "              whether in tort (including negligence), contract, or otherwise,\n",
            "              unless required by applicable law (such as deliberate and grossly\n",
            "              negligent acts) or agreed to in writing, shall any Contributor be\n",
            "              liable to You for damages, including any direct, indirect, special,\n",
            "              incidental, or consequential damages of any character arising as a\n",
            "              result of this License or out of the use or inability to use the\n",
            "              Work (including but not limited to damages for loss of goodwill,\n",
            "              work stoppage, computer failure or malfunction, or any and all\n",
            "              other commercial damages or losses), even if such Contributor\n",
            "              has been advised of the possibility of such damages.\n",
            "        \n",
            "           9. Accepting Warranty or Additional Liability. While redistributing\n",
            "              the Work or Derivative Works thereof, You may choose to offer,\n",
            "              and charge a fee for, acceptance of support, warranty, indemnity,\n",
            "              or other liability obligations and/or rights consistent with this\n",
            "              License. However, in accepting such obligations, You may act only\n",
            "              on Your own behalf and on Your sole responsibility, not on behalf\n",
            "              of any other Contributor, and only if You agree to indemnify,\n",
            "              defend, and hold each Contributor harmless for any liability\n",
            "              incurred by, or claims asserted against, such Contributor by reason\n",
            "              of your accepting any such warranty or additional liability.\n",
            "        \n",
            "           END OF TERMS AND CONDITIONS\n",
            "        \n",
            "           APPENDIX: How to apply the Apache License to your work.\n",
            "        \n",
            "              To apply the Apache License to your work, attach the following\n",
            "              boilerplate notice, with the fields enclosed by brackets \"[]\"\n",
            "              replaced with your own identifying information. (Don't include\n",
            "              the brackets!)  The text should be enclosed in the appropriate\n",
            "              comment syntax for the file format. We also recommend that a\n",
            "              file or class name and description of purpose be included on the\n",
            "              same \"printed page\" as the copyright notice for easier\n",
            "              identification within third-party archives.\n",
            "        \n",
            "           Copyright [2024-] [Unsloth AI, Daniel Han-Chen & Michael Han-Chen]\n",
            "        \n",
            "           Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "           you may not use this file except in compliance with the License.\n",
            "           You may obtain a copy of the License at\n",
            "        \n",
            "               http://www.apache.org/licenses/LICENSE-2.0\n",
            "        \n",
            "           Unless required by applicable law or agreed to in writing, software\n",
            "           distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "           WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "           See the License for the specific language governing permissions and\n",
            "           limitations under the License.\n",
            "        \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Loading Pre-trained Models with Unsloth\n",
        "\n",
        "### Loading Pre-trained Models with Unsloth\n",
        "\n",
        "The following script demonstrates how to load a pre-trained model using Unsloth's `FastLanguageModel`. `FastLanguageModel` is a utility from UnSloth for efficiently loading and using pre-trained language models. It simplifies model loading, configuration, and tokenizer integration, making it ideal for tasks like text generation, classification, and summarization.\n",
        "\n",
        "We can use a variety of pre-trained models suitable for different applications.\n",
        "Available models are **Llama 3.1 (8B), Llama 3.2 (1B + 3B), Mistral NeMo (12B), Gemma 2 (9B), Qwen 2.5 (7B), Mistral Small (22B), Inference Chat UI, Phi-3.5 (Mini), Llama 3 (8B), Mistral v0.3 (7B), Phi-3 (Medium), Qwen2 (7B), Gemma 2 (2B), TinyLlama**. For more details, visit [Model Documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n",
        "\n",
        "\n",
        "This script demonstrates how to load a pre-trained model using Unsloth's `FastLanguageModel` with optimized settings.\n",
        "\n",
        "#### Configuration:\n",
        "- **`max_seq_length`**: Maximum input sequence length (2048).\n",
        "- **`dtype`**: Data type for model weights (default: `None`).\n",
        "- **`load_in_4bit`**: Enables 4-bit precision for efficient memory and speed.\n",
        "\n",
        "In this particular example, we load a pre-trained 3.2B parameter Llama model variant  along with its corresponding tokenizer for text processing. You can change model and data as per requirement.\n"
      ],
      "metadata": {
        "id": "r0xrn0whXJug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Configuration parameters\n",
        "max_seq_length = 2048  # Maximum sequence length for inputs\n",
        "dtype = None           # Data type for model weights (default: None)\n",
        "load_in_4bit = True    # Use 4-bit precision to optimize memory and speed\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/Llama-3.2-3B-bnb-4bit\",  # Specify the model\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5fne_xjX6N6",
        "outputId": "bceff823-5ae4-428d-cb1f-3b322e1ad8c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.12.2: Fast Llama patching. Transformers:4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Configuring a PEFT Model\n",
        "\n",
        "The following code demonstrates how to configure a parameter-efficient fine-tuning (PEFT) model using the `FastLanguageModel.get_peft_model` method:\n",
        "#### Purpose\n",
        "The `FastLanguageModel.get_peft_model` function simplifies the fine-tuning of large language models by employing Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRA (Low-Rank Adaptation). This method reduces resource usage while maintaining performance.\n",
        "\n",
        "#### Parameters\n",
        "1. **`model`**: The base model to be fine-tuned. This is typically a pre-trained large language model.\n",
        "2. **`r`**: The rank of the low-rank adaptation matrices. This value determines the number of trainable parameters, balancing efficiency and flexibility. In this example, `r=16`.\n",
        "3. **`target_modules`**: A list of specific modules within the model to which LoRA should be applied. Modules like `q_proj`, `k_proj`, `v_proj`, and others represent key projections or transformations in transformer architectures.\n",
        "4. **`lora_alpha`**: A scaling factor for the LoRA layers. This helps regulate the magnitude of updates from the adapted layers. The value here is set to `16`.\n",
        "5. **`lora_dropout`**: Specifies the dropout rate for the LoRA layers. A value of `0` means no dropout is applied, ensuring all connections remain active during training.\n",
        "6. **`bias`**: Determines how biases are treated during fine-tuning:\n",
        "   - `\"none\"`: Biases remain frozen.\n",
        "   - `\"all\"`: All biases are trainable.\n",
        "   - `\"layerwise\"`: Biases are selectively trainable per layer.\n",
        "7. **`use_gradient_checkpointing`**: Activates memory-efficient training by checkpointing intermediate activations during backpropagation. The `\"unsloth\"` value indicates a custom configuration.\n",
        "8. **`random_state`**: A seed value (e.g., `3407`) used to ensure reproducibility in the training process.\n",
        "9. **`use_rslora`**: Indicates whether to use Randomized SVD (Singular Value Decomposition) for LoRA. In this case, it is set to `False`.\n",
        "10. **`loftq_config`**: Specifies an optional configuration for LOFT-Q quantization. Set to `None` if not applicable.\n",
        "\n"
      ],
      "metadata": {
        "id": "d6ndIeb-cGFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9jvfq5BcDLA",
        "outputId": "868433fa-8b56-43ca-cd29-edd8aa01ac71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.12.2 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Sentiment Analysis Use case\n",
        "\n",
        "This workflow processes a sentiment dataset to create conversation-style inputs for a chat-based LLM. It leverages the `unsloth` library for template application and the HuggingFace `Dataset` library for dataset formatting. The objective is to generate prompts and responses that facilitate sentiment analysis.\n",
        "\n",
        "#### Overview\n",
        "\n",
        "1. **Dataset Preparation**  \n",
        "   The script loads a sentiment dataset (`dataset-sentiment.csv`) into a Pandas DataFrame and randomly samples 1,000 rows for manageable processing.\n",
        "\n",
        "2. **Label Conversion**  \n",
        "   Sentiment labels (`positive`, `neutral`, `negative`) are mapped to numerical values (`2`, `1`, `0`) for uniformity and downstream compatibility.\n",
        "\n",
        "3. **Prompt Creation**  \n",
        "   A custom function generates detailed prompts for each text entry. These prompts ask the model to analyze sentiment based on:\n",
        "   - Emotional language\n",
        "   - Positive/negative expressions\n",
        "   - Tone shifts or balanced tone\n",
        "\n",
        "4. **Response Generation**  \n",
        "   A predefined function produces responses based on the sentiment labels, providing reasoning for the assessments.\n",
        "\n",
        "5. **Conversation Structuring**  \n",
        "   Each dataset entry is transformed into a structured conversation:\n",
        "   - **System Role**: Sets the context for the model (e.g., \"You are a financial sentiment analyzer\").\n",
        "   - **User Role**: Provides the sentiment analysis prompt.\n",
        "   - **Assistant Role**: Supplies the sentiment assessment response.\n",
        "\n",
        "6. **Conversion to HuggingFace Dataset**  \n",
        "   The structured DataFrame is converted into a HuggingFace `Dataset` for compatibility with transformer models.\n",
        "\n",
        "7. **Chat Template Formatting**  \n",
        "   Conversations are processed using the `unsloth` chat template, formatted as input for an LLM. This ensures consistent tokenization and structure.\n",
        "\n",
        "## Final Output\n",
        "\n",
        "The script produces a HuggingFace-compatible dataset with conversation-style prompts and responses. These are ready for use in training or evaluating sentiment analysis tasks.\n"
      ],
      "metadata": {
        "id": "8thhylIhgnfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "# Apply chat template\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "# Load and prepare dataset\n",
        "# df = pd.read_csv(\"/content/dataset-sentiment.csv\")\n",
        "df = pd.read_csv(\"/content/sample.csv\")\n",
        "\n",
        "# Sample 1000 random rows\n",
        "# df = df.sample(n=1000, random_state=42)\n",
        "\n",
        "# Convert labels to numerical format\n",
        "label_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "df['label_num'] = df['label'].map(label_map)\n",
        "\n",
        "def create_prompt(text):\n",
        "    return f\"\"\"Assess the sentiment of the following text by identifying the presence of sentiment indicators such as emotional language, positive or negative expressions, and tone shifts.\n",
        "\n",
        "If you find strong sentiment indicators, mark them accordingly and provide a reasoning for why the sentiment is positive, negative, or neutral.\n",
        "\n",
        "Now, assess the following text:\n",
        "\n",
        "Text: {text}\n",
        "\n",
        "Sentiment Indicators Checklist:\n",
        "- Emotional Language: Uses words that convey strong feelings, such as joy, anger, sadness, or excitement.\n",
        "- Positive Expressions: Words or phrases that promote positive feelings, praise, or optimism.\n",
        "- Negative Expressions: Words or phrases that convey criticism, pessimism, or negative attitudes.\n",
        "- Tone Shifts: Noticeable changes in tone that affect how the content is perceived, potentially altering the sentiment.\n",
        "- Balanced or Neutral Tone: Absence of strong emotional language, implying a more neutral or objective sentiment.\n",
        "\n",
        "Provide three separate assessments of the sentiment in the following text. Each assessment should be in the format:\n",
        "\n",
        "[NUMBER]. [SENTIMENT] - [REASONING]\n",
        "\n",
        "Where [NUMBER] is 1, 2, or 3, [SENTIMENT] is 'Positive', 'Negative', or 'Neutral', and [REASONING] is a one-line explanation for the chosen sentiment.\"\"\"\n",
        "\n",
        "def create_response(label):\n",
        "    return f\"\"\"1. {label.upper()} - Analysis based on the text's indicators and tone.\n",
        "2. {label.upper()} - Evaluation of language and contextual elements.\n",
        "3. {label.upper()} - Assessment of overall sentiment impact.\"\"\"\n",
        "\n",
        "# Create conversation format\n",
        "def create_conversation(row):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are a financial sentiment analyzer. Your task is to assess text sentiment with detailed reasoning.\"},\n",
        "        {\"role\": \"user\", \"content\": create_prompt(row['text'])},\n",
        "        {\"role\": \"assistant\", \"content\": create_response(row['label'])}\n",
        "    ]\n",
        "\n",
        "df['conversations'] = df.apply(create_conversation, axis=1)\n",
        "\n",
        "# Convert to HuggingFace dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Format prompts\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
        "            for convo in convos]\n",
        "    return {\"text\": texts}\n",
        "\n",
        "# Format the dataset\n",
        "formatted_dataset = dataset.map(\n",
        "    formatting_prompts_func,\n",
        "    batched=True,\n",
        "    remove_columns=dataset.column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "41d980ceb0af46fbb05dad061ad2d380",
            "f7aa60185e554956895355ce7f872096",
            "8dbeee2a1bf54f6f88a29655de4e5d3a",
            "f2acb18b9278454885ab1a04d59504a7",
            "ef70d5964d9f4d27aeebc1ab78606581",
            "1778cef7edbe46819ef5e2fd89aac7a5",
            "41fa5f5c63ed45f48f06952db7234fec",
            "0ee0ac9b01a844ef880a2c0ba1ce57c5",
            "cfcfc120792341df9c59f47976dd8549",
            "534e6e7b81a04d558cff20028bc86812",
            "e12227e9feab4a518c61f0abc292d02e"
          ]
        },
        "id": "Jo6DibHeaPmb",
        "outputId": "6be3b5bc-4d4a-4dd3-a52c-39f9222a11f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/627 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41d980ceb0af46fbb05dad061ad2d380"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6:  Fine-Tuning Documentation with `SFTTrainer`\n",
        "\n",
        "This workflow demonstrates how to fine-tune a model using the `SFTTrainer` class from the `trl` library. The configuration optimizes for small batch sizes, mixed-precision training, and efficient sequence handling.\n",
        "\n",
        "#### Key Components\n",
        "\n",
        "#### Libraries and Utilities\n",
        "- **`SFTTrainer`**: Simplifies supervised fine-tuning for transformer models.\n",
        "- **`TrainingArguments`**: Manages hyperparameters and training configurations.\n",
        "- **`DataCollatorForSeq2Seq`**: Prepares data for sequence-to-sequence tasks.\n",
        "- **`is_bfloat16_supported`**: Dynamically checks if the current environment supports BF16 precision.\n",
        "\n",
        "---\n",
        "\n",
        "#### Workflow Breakdown\n",
        "\n",
        "1. **Model and Dataset**  \n",
        "   - The `SFTTrainer` requires a `model`, `tokenizer`, and `train_dataset`. The dataset's text field is specified using `dataset_text_field`.\n",
        "\n",
        "2. **Data Collation**  \n",
        "   - `DataCollatorForSeq2Seq` ensures that input sequences are tokenized and padded to the required `max_seq_length`.\n",
        "\n",
        "3. **Training Configuration**  \n",
        "   - **Key Parameters**:\n",
        "     - `per_device_train_batch_size`: Number of samples per device during training (set to `2`).\n",
        "     - `gradient_accumulation_steps`: Number of updates to accumulate gradients before optimizing.\n",
        "     - `learning_rate`: Initial learning rate for the optimizer (`2e-4`).\n",
        "     - `fp16` and `bf16`: Mixed-precision settings for faster training and lower memory usage, automatically chosen based on system support.\n",
        "     - `max_steps`: Maximum training steps (`60` in this example).\n",
        "     - `logging_steps`: Frequency of training logs (`1` step).\n",
        "     - `optim`: Optimizer type (`adamw_8bit` for efficient memory usage).\n",
        "     - `weight_decay`: Regularization parameter for weight decay (`0.01`).\n",
        "     - `lr_scheduler_type`: Learning rate scheduler (`linear`).\n",
        "     - `seed`: Ensures reproducibility (`3407`).\n",
        "     - `output_dir`: Directory to save outputs (`outputs`).\n",
        "\n",
        "4. **Sequence Packing**  \n",
        "   - Disabled (`packing = False`) for better handling of short sequences. When enabled, it can accelerate training up to 5x by efficiently packing sequences.\n",
        "\n",
        "5. **Output and Reporting**  \n",
        "   - Logs are saved locally (`output_dir`) without reporting to external tools like WandB (`report_to = \"none\"`). This can be modified for integration with monitoring platforms.\n",
        "\n",
        "---\n",
        "\n",
        "#### Advantages of this Configuration\n",
        "\n",
        "1. **Efficient Training**:  \n",
        "   - Small batch sizes and gradient accumulation allow training on systems with limited GPU memory.\n",
        "   - Mixed precision (`fp16` or `bf16`) accelerates training while saving memory.\n",
        "\n",
        "2. **Dynamic Precision Handling**:  \n",
        "   - Automatically determines the best precision (FP16 or BF16) based on hardware support.\n",
        "\n",
        "3. **Customizable and Lightweight**:  \n",
        "   - Parameters like `max_steps`, `learning_rate`, and `logging_steps` allow flexible tuning for small or large-scale training runs.\n",
        "\n",
        "4. **Optimized for Short Sequences**:  \n",
        "   - Option to enable sequence packing to maximize GPU utilization and reduce training time.\n",
        "\n",
        "---\n",
        "\n",
        "## Notes\n",
        "\n",
        "- **Extending Training**: Uncomment `num_train_epochs` to specify epoch-based training instead of step-based training.\n",
        "- **Monitoring Tools**: Replace `\"none\"` in `report_to` with tools like `\"wandb\"` for real-time tracking and visualization.\n",
        "- **Sequence Packing**: While disabled by default, enabling it is recommended for datasets with very short sequences.\n",
        "\n",
        "This setup is ideal for fine-tuning LLMs on modest hardware while maintaining flexibility for advanced configurations.\n"
      ],
      "metadata": {
        "id": "skcxS7NFiooJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d06eac2f904145b78b093d5a3e489030",
            "64b235ff255346f7a6608016d03fcefc",
            "059c7ab03a6e4a889b5208a632af85c3",
            "85e15b6fa0a44954957bf4126936bc56",
            "bf4e754bcc6d4422bc2184203d3de6b1",
            "23becbea9b3d4a8188789a3fb3abda8e",
            "ad4ce66e11124b6bad3a666b7927b170",
            "016bf3cda55f4429a928d16c949176c3",
            "bad0246fcfe248baa57fbc3d358df08b",
            "41837ed3a4e34995a576bd174aaec877",
            "3be8358daaaf49458281199d2bdcbc7c"
          ]
        },
        "id": "luB0aEcSjeeC",
        "outputId": "05e4e13a-7f64-41f9-b784-15e3226aa7ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/627 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d06eac2f904145b78b093d5a3e489030"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on Responses Only with `unsloth.chat_templates`\n",
        "\n",
        "The `train_on_responses_only` utility from `unsloth.chat_templates` is used to focus the training process on the assistant's responses, while preserving the user instructions as context. This is particularly useful when fine-tuning conversational models where the primary interest is improving response quality.\n",
        "\n",
        "---\n",
        "\n",
        "## Functionality Overview\n",
        "\n",
        "- **Purpose**: Modifies the training dataset to include only the assistant's responses for optimization, while retaining the user instructions for input context.\n",
        "- **Integration**: Used in conjunction with a preconfigured `SFTTrainer` or similar training setup.\n",
        "\n",
        "---\n",
        "\n",
        "#### Key Components\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "1. **`trainer`**  \n",
        "   - The existing trainer instance configured for supervised fine-tuning.\n",
        "   - Carries the model, tokenizer, dataset, and training arguments.\n",
        "\n",
        "2. **`instruction_part`**  \n",
        "   - Specifies the token delimiter for user instructions.  \n",
        "   - Example: `<|start_header_id|>user<|end_header_id|>\\n\\n` marks the user input section.\n",
        "\n",
        "3. **`response_part`**  \n",
        "   - Specifies the token delimiter for assistant responses.  \n",
        "   - Example: `<|start_header_id|>assistant<|end_header_id|>\\n\\n` marks the assistant's response section.\n",
        "\n",
        "---\n",
        "\n",
        "#### Workflow\n",
        "\n",
        "1. **Preparation**  \n",
        "   - Ensure the training dataset includes conversations formatted with clear demarcations for user and assistant roles.  \n",
        "   - The delimiters (`instruction_part` and `response_part`) help the model focus on the assistant's responses.\n",
        "\n",
        "2. **Applying the Utility**  \n",
        "   - Pass the trainer instance and delimiters to `train_on_responses_only`.  \n",
        "   - This modifies the training focus, reducing unnecessary computation on the user input while ensuring the assistant’s responses are optimized.\n",
        "\n",
        "3. **Training Process**  \n",
        "   - The modified trainer continues training, emphasizing the assistant's part in the conversation, which is critical for generating high-quality responses.\n",
        "\n",
        "---\n",
        "\n",
        "#### Example Use Case\n",
        "\n",
        "In a typical chat-based training scenario:\n",
        "- The dataset contains structured conversations between a user and an assistant.\n",
        "- The assistant’s responses are the primary output of interest.\n",
        "- Using `train_on_responses_only`, the model focuses on the response part, improving efficiency and relevance during training.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "RXixJnypkLPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aaaede9f154343f6b8ea518918ac6ab6",
            "d86d8f9b25914770bf1064c5bf9bb375",
            "157f388119e24237bc5aca555c94d656",
            "de19ee818f6e4edfa4538bcd363c84c6",
            "b510619679904ebabde226b705f092de",
            "fbd7e54da10f4342807cde0e84b1183c",
            "fedf8959c41f41b89cc95bb2356e2d34",
            "c0b66895e7274d78b3d0875cc793a8df",
            "883443f49be94fcba5b6198d54e64633",
            "c795a1a5eb7f4914a97b9bedfe1e79eb",
            "6e7a3883517b49f88d35248d372fb7aa"
          ]
        },
        "id": "sNnzHaWakKzA",
        "outputId": "9a312ea2-92c3-47ea-fd64-beaa89f6f3f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/627 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaaede9f154343f6b8ea518918ac6ab6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NcnjEUDWlOAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code displays GPU details and memory usage using PyTorch. It shows the GPU name, total memory capacity, and peak memory reserved during the session,\n",
        "# helping monitor resource utilization.\n",
        "\n",
        "import torch\n",
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JU6LHAulOS8",
        "outputId": "c5ff2b5e-e0b9-40aa-be7c-6ccbf78d2de8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "5.086 GB of memory reserved.\n"
          ]
        }
      ]
    }
  ]
}