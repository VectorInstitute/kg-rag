{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG-based Question Answering\n",
    "\n",
    "This notebook demonstrates using the langchain-graphrag library to implement a knowledge graph-based RAG system.\n",
    "\n",
    "The approach involves:\n",
    "1. Text extraction and splitting into units\n",
    "2. Graph generation using entity and relationship extraction\n",
    "3. Graph community detection\n",
    "4. Question answering using either local or global search strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "from langchain_graphrag.indexing import SimpleIndexer, TextUnitExtractor\n",
    "from langchain_graphrag.indexing.artifacts_generation import (\n",
    "    CommunitiesReportsArtifactsGenerator,\n",
    "    EntitiesArtifactsGenerator, \n",
    "    RelationshipsArtifactsGenerator,\n",
    "    TextUnitsArtifactsGenerator\n",
    ")\n",
    "from langchain_graphrag.indexing.graph_clustering import HierarchicalLeidenCommunityDetector\n",
    "from langchain_graphrag.indexing.graph_generation import (\n",
    "    EntityRelationshipExtractor,\n",
    "    EntityRelationshipDescriptionSummarizer,\n",
    "    GraphGenerator,\n",
    "    GraphsMerger\n",
    ")\n",
    "from langchain_graphrag.indexing.report_generation import (\n",
    "    CommunityReportGenerator,\n",
    "    CommunityReportWriter\n",
    ")\n",
    "from langchain_graphrag.types.graphs.community import CommunityLevel\n",
    "from langchain_graphrag.utils import TiktokenCounter\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Setup paths\n",
    "CACHE_DIR = Path(\"cache\")\n",
    "VECTOR_STORE_DIR = Path(\"vector_stores\") \n",
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "\n",
    "for p in [CACHE_DIR, VECTOR_STORE_DIR, ARTIFACTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Environment and Models\n",
    "\n",
    "Set up the required models and environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLMs\n",
    "er_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.0,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    cache=SQLiteCache(str(CACHE_DIR / \"openai_cache.db\")),\n",
    ")\n",
    "\n",
    "es_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\", \n",
    "    temperature=0.0,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    cache=SQLiteCache(str(CACHE_DIR / \"openai_cache.db\")),\n",
    ")\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Create vector store for entities\n",
    "entities_vector_store = Chroma(\n",
    "    collection_name=\"sec-10q-entities\",\n",
    "    persist_directory=str(VECTOR_STORE_DIR),\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Setup text splitter and extractor\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "text_unit_extractor = TextUnitExtractor(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Graph Components\n",
    "\n",
    "Set up the components needed for graph generation and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity relationship extraction and summarization\n",
    "entity_extractor = EntityRelationshipExtractor.build_default(llm=er_llm)\n",
    "entity_summarizer = EntityRelationshipDescriptionSummarizer.build_default(llm=es_llm)\n",
    "\n",
    "# Graph generator\n",
    "graph_generator = GraphGenerator(\n",
    "    er_extractor=entity_extractor,\n",
    "    graphs_merger=GraphsMerger(),\n",
    "    er_description_summarizer=entity_summarizer\n",
    ")\n",
    "\n",
    "# Community detector\n",
    "community_detector = HierarchicalLeidenCommunityDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Artifacts Generators\n",
    "\n",
    "Set up components for generating various artifacts from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create artifacts generators\n",
    "entities_artifacts_generator = EntitiesArtifactsGenerator(\n",
    "    entities_vector_store=entities_vector_store\n",
    ")\n",
    "\n",
    "relationships_artifacts_generator = RelationshipsArtifactsGenerator()\n",
    "\n",
    "report_generator = CommunityReportGenerator.build_default(llm=er_llm)\n",
    "report_writer = CommunityReportWriter()\n",
    "\n",
    "communities_report_artifacts_generator = CommunitiesReportsArtifactsGenerator(\n",
    "    report_generator=report_generator,\n",
    "    report_writer=report_writer\n",
    ")\n",
    "\n",
    "text_units_artifacts_generator = TextUnitsArtifactsGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Documents\n",
    "\n",
    "Load the input text and split it into manageable units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the documents\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "documents = []\n",
    "docs_path = Path(\"../../data/sec-10-q/docs\")\n",
    "\n",
    "# Load PDF documents\n",
    "for filename in os.listdir(docs_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = docs_path / filename\n",
    "        try:\n",
    "            docs = PyPDFLoader(str(file_path)).load()\n",
    "            documents.extend(docs)\n",
    "            print(f\"Processed: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Indexer and Generate Artifacts\n",
    "\n",
    "Initialize the indexer and process the documents to generate all required artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the indexer\n",
    "indexer = SimpleIndexer(\n",
    "    text_unit_extractor=text_unit_extractor,\n",
    "    graph_generator=graph_generator,\n",
    "    community_detector=community_detector,\n",
    "    entities_artifacts_generator=entities_artifacts_generator,\n",
    "    relationships_artifacts_generator=relationships_artifacts_generator,\n",
    "    text_units_artifacts_generator=text_units_artifacts_generator,\n",
    "    communities_report_artifacts_generator=communities_report_artifacts_generator\n",
    ")\n",
    "\n",
    "# Run indexing\n",
    "artifacts = indexer.run(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# save artifacts to .pkl on disk\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('graphrag_artifacts.pkl', 'wb') as f:\n",
    "    pickle.dump(artifacts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Search Example\n",
    "\n",
    "Demonstrate using the local search capability for answering specific questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "from langchain_graphrag.query.local_search import (\n",
    "    LocalSearch,\n",
    "    LocalSearchPromptBuilder,\n",
    "    LocalSearchRetriever,\n",
    ")\n",
    "from langchain_graphrag.query.local_search.context_builders import ContextBuilder\n",
    "from langchain_graphrag.query.local_search.context_selectors import ContextSelector\n",
    "from langchain_graphrag.query.local_search._system_prompt import LOCAL_SEARCH_SYSTEM_PROMPT\n",
    "\n",
    "PROMPT_SUFFIX = f\"\"\"\n",
    "Important Rules:\n",
    "- Base your answer ONLY on the provided context\n",
    "- Do not make assumptions or use external knowledge besides the context provided\n",
    "- Numbers must be whole integers without comma separators, unless specified\n",
    "- Percentages must be whole numbers without % sign\n",
    "- The answer field must contain ONLY the numerical value, no text or units\n",
    "- Your entire response must be valid JSON\n",
    "\n",
    "The current date is {current_date}.\n",
    "\"\"\"\n",
    "\n",
    "LOCAL_SEARCH_SYSTEM_PROMPT = LOCAL_SEARCH_SYSTEM_PROMPT + PROMPT_SUFFIX\n",
    "\n",
    "# Create components for local search\n",
    "context_selector = ContextSelector.build_default(\n",
    "    entities_vector_store=entities_vector_store,\n",
    "    entities_top_k=10,\n",
    "    community_level=cast(CommunityLevel, 2)\n",
    ")\n",
    "\n",
    "context_builder = ContextBuilder.build_default(\n",
    "    token_counter=TiktokenCounter(),\n",
    ")\n",
    "\n",
    "retriever = LocalSearchRetriever(\n",
    "    context_selector=context_selector,\n",
    "    context_builder=context_builder,\n",
    "    artifacts=artifacts,\n",
    ")\n",
    "\n",
    "local_search = LocalSearch(\n",
    "    prompt_builder=LocalSearchPromptBuilder(system_prompt=LOCAL_SEARCH_SYSTEM_PROMPT, show_references=True),\n",
    "    llm=er_llm,\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "search_chain = local_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search_chain.invoke(\"What was the total net sales for Apple for the quarterly period ended April 1, 2023, as reported in their 2023 Q2 AAPL.pdf? Provide the answer in millions of dollars as a whole number without commas.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = search_chain.invoke(\"What was the total net sales for Apple for the quarterly period ended April 1, 2023, as reported in their 2023 Q2 AAPL.pdf? Provide the answer in millions of dollars as a whole number without commas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation code\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def extract_number(text):\n",
    "    # Find any number (integer or decimal) in the string\n",
    "    match = re.search(r':\\s*(-?\\d+(?:\\.\\d+)?)', text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Create evaluation results directory if it doesn't exist\n",
    "eval_dir = Path(\"evaluation_results_graphrag\")\n",
    "eval_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create timestamp for unique filename\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = eval_dir / f\"evaluation_results_{timestamp}.txt\"\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"../../data/sec-10-q/synthetic_qna_data_7_gpt4o_v2_mod1.csv\")\n",
    "\n",
    "# Prepare results storage\n",
    "results = []\n",
    "correct = 0\n",
    "total = len(df)\n",
    "\n",
    "# Open file for writing results\n",
    "with open(output_file, 'w') as f:\n",
    "    # Write header information\n",
    "    f.write(\"SEC 10-Q RAG System Evaluation Results\\n\")\n",
    "    f.write(f\"Evaluation Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Total Questions: {total}\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    # Evaluate each question\n",
    "    for i, row in tqdm(df.iterrows(), total=total, desc=\"Evaluating questions\"):\n",
    "        question = row[\"New Question\"]\n",
    "        expected_answer = row[\"New Answer\"]\n",
    "        \n",
    "        # Get model response\n",
    "        try:\n",
    "            response = search_chain.invoke(question)\n",
    "            model_answer = extract_number(response)\n",
    "            is_correct = float(model_answer) == float(expected_answer)\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "        except Exception as e:\n",
    "            model_answer = f\"ERROR: {str(e)}\"\n",
    "            model_reasoning = \"Error occurred during processing\"\n",
    "            is_correct = False\n",
    "        \n",
    "        # Write question details\n",
    "        f.write(f\"Question {i+1}/{total}:\\n\")\n",
    "        f.write(f\"Question: {question}\\n\")\n",
    "        f.write(f\"Expected Answer: {expected_answer}\\n\")\n",
    "        f.write(f\"Model Answer: {model_answer}\\n\")\n",
    "        f.write(f\"Correct: {is_correct}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        # Store result for summary\n",
    "        results.append({\n",
    "            'question_id': i+1,\n",
    "            'question': question,\n",
    "            'expected': expected_answer,\n",
    "            'response': model_answer,\n",
    "            'correct': is_correct\n",
    "        })\n",
    "    \n",
    "    # Calculate and write summary statistics\n",
    "    accuracy = correct / total\n",
    "    f.write(\"\\nEvaluation Summary\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(f\"Total Questions: {total}\\n\")\n",
    "    f.write(f\"Correct Answers: {correct}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.2%}\\n\")\n",
    "\n",
    "# Create results DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(eval_dir / f\"evaluation_detailed_results_{timestamp}.csv\", index=False)\n",
    "\n",
    "print(f\"Evaluation complete. Results saved to {output_file}\")\n",
    "print(f\"Detailed results saved to {eval_dir}/evaluation_detailed_results_{timestamp}.csv\")\n",
    "print(f\"\\nFinal Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Search Example\n",
    "\n",
    "Demonstrate using the global search capability for broader questions about the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_graphrag.query.global_search import GlobalSearch\n",
    "from langchain_graphrag.query.global_search.community_weight_calculator import (\n",
    "    CommunityWeightCalculator\n",
    ")\n",
    "from langchain_graphrag.query.global_search.key_points_aggregator import (\n",
    "    KeyPointsAggregator,\n",
    "    KeyPointsAggregatorPromptBuilder,\n",
    "    KeyPointsContextBuilder,\n",
    ")\n",
    "from langchain_graphrag.query.global_search.key_points_generator import (\n",
    "    CommunityReportContextBuilder,\n",
    "    KeyPointsGenerator,\n",
    "    KeyPointsGeneratorPromptBuilder,\n",
    ")\n",
    "\n",
    "# Create components for global search\n",
    "report_context_builder = CommunityReportContextBuilder(\n",
    "    community_level=cast(CommunityLevel, 2),\n",
    "    weight_calculator=CommunityWeightCalculator(),\n",
    "    artifacts=artifacts,\n",
    "    token_counter=TiktokenCounter(),\n",
    ")\n",
    "\n",
    "kp_generator = KeyPointsGenerator(\n",
    "    llm=er_llm,\n",
    "    prompt_builder=KeyPointsGeneratorPromptBuilder(show_references=True),\n",
    "    context_builder=report_context_builder,\n",
    ")\n",
    "\n",
    "kp_aggregator = KeyPointsAggregator(\n",
    "    llm=er_llm,\n",
    "    prompt_builder=KeyPointsAggregatorPromptBuilder(show_references=True),\n",
    "    context_builder=KeyPointsContextBuilder(\n",
    "        token_counter=TiktokenCounter(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "global_search = GlobalSearch(\n",
    "    kp_generator=kp_generator,\n",
    "    kp_aggregator=kp_aggregator\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
