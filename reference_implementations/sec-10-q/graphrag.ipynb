{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG-based Question Answering\n",
    "\n",
    "This notebook demonstrates using the langchain-graphrag library to implement a knowledge graph-based RAG system.\n",
    "\n",
    "The approach involves:\n",
    "1. Text extraction and splitting into units\n",
    "2. Graph generation using entity and relationship extraction\n",
    "3. Graph community detection\n",
    "4. Question answering using either local or global search strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "from langchain_graphrag.indexing import SimpleIndexer, TextUnitExtractor\n",
    "from langchain_graphrag.indexing.artifacts_generation import (\n",
    "    CommunitiesReportsArtifactsGenerator,\n",
    "    EntitiesArtifactsGenerator, \n",
    "    RelationshipsArtifactsGenerator,\n",
    "    TextUnitsArtifactsGenerator\n",
    ")\n",
    "from langchain_graphrag.indexing.graph_clustering import HierarchicalLeidenCommunityDetector\n",
    "from langchain_graphrag.indexing.graph_generation import (\n",
    "    EntityRelationshipExtractor,\n",
    "    EntityRelationshipDescriptionSummarizer,\n",
    "    GraphGenerator,\n",
    "    GraphsMerger\n",
    ")\n",
    "from langchain_graphrag.indexing.report_generation import (\n",
    "    CommunityReportGenerator,\n",
    "    CommunityReportWriter\n",
    ")\n",
    "from langchain_graphrag.types.graphs.community import CommunityLevel\n",
    "from langchain_graphrag.utils import TiktokenCounter\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Setup paths\n",
    "CACHE_DIR = Path(\"cache\")\n",
    "VECTOR_STORE_DIR = Path(\"vector_stores\") \n",
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "\n",
    "for p in [CACHE_DIR, VECTOR_STORE_DIR, ARTIFACTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Environment and Models\n",
    "\n",
    "Set up the required models and environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLMs\n",
    "er_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.0,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    cache=SQLiteCache(str(CACHE_DIR / \"openai_cache.db\")),\n",
    ")\n",
    "\n",
    "es_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\", \n",
    "    temperature=0.0,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    cache=SQLiteCache(str(CACHE_DIR / \"openai_cache.db\")),\n",
    ")\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Create vector store for entities\n",
    "entities_vector_store = Chroma(\n",
    "    collection_name=\"sec-10q-entities\",\n",
    "    persist_directory=str(VECTOR_STORE_DIR),\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Setup text splitter and extractor\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "text_unit_extractor = TextUnitExtractor(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Graph Components\n",
    "\n",
    "Set up the components needed for graph generation and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity relationship extraction and summarization\n",
    "entity_extractor = EntityRelationshipExtractor.build_default(llm=er_llm)\n",
    "entity_summarizer = EntityRelationshipDescriptionSummarizer.build_default(llm=es_llm)\n",
    "\n",
    "# Graph generator\n",
    "graph_generator = GraphGenerator(\n",
    "    er_extractor=entity_extractor,\n",
    "    graphs_merger=GraphsMerger(),\n",
    "    er_description_summarizer=entity_summarizer\n",
    ")\n",
    "\n",
    "# Community detector\n",
    "community_detector = HierarchicalLeidenCommunityDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Artifacts Generators\n",
    "\n",
    "Set up components for generating various artifacts from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create artifacts generators\n",
    "entities_artifacts_generator = EntitiesArtifactsGenerator(\n",
    "    entities_vector_store=entities_vector_store\n",
    ")\n",
    "\n",
    "relationships_artifacts_generator = RelationshipsArtifactsGenerator()\n",
    "\n",
    "report_generator = CommunityReportGenerator.build_default(llm=er_llm)\n",
    "report_writer = CommunityReportWriter()\n",
    "\n",
    "communities_report_artifacts_generator = CommunitiesReportsArtifactsGenerator(\n",
    "    report_generator=report_generator,\n",
    "    report_writer=report_writer\n",
    ")\n",
    "\n",
    "text_units_artifacts_generator = TextUnitsArtifactsGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Documents\n",
    "\n",
    "Load the input text and split it into manageable units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the documents\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "documents = []\n",
    "docs_path = Path(\"../../data/sec-10-q/docs\")\n",
    "\n",
    "# Load PDF documents\n",
    "for filename in os.listdir(docs_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = docs_path / filename\n",
    "        try:\n",
    "            docs = PyPDFLoader(str(file_path)).load()\n",
    "            documents.extend(docs)\n",
    "            print(f\"Processed: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Indexer and Generate Artifacts\n",
    "\n",
    "Initialize the indexer and process the documents to generate all required artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the indexer\n",
    "indexer = SimpleIndexer(\n",
    "    text_unit_extractor=text_unit_extractor,\n",
    "    graph_generator=graph_generator,\n",
    "    community_detector=community_detector,\n",
    "    entities_artifacts_generator=entities_artifacts_generator,\n",
    "    relationships_artifacts_generator=relationships_artifacts_generator,\n",
    "    text_units_artifacts_generator=text_units_artifacts_generator,\n",
    "    communities_report_artifacts_generator=communities_report_artifacts_generator\n",
    ")\n",
    "\n",
    "# Run indexing\n",
    "artifacts = indexer.run(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Search Example\n",
    "\n",
    "Demonstrate using the local search capability for answering specific questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_graphrag.query.local_search import (\n",
    "    LocalSearch,\n",
    "    LocalSearchPromptBuilder,\n",
    "    LocalSearchRetriever,\n",
    ")\n",
    "from langchain_graphrag.query.local_search.context_builders import ContextBuilder\n",
    "from langchain_graphrag.query.local_search.context_selectors import ContextSelector\n",
    "\n",
    "# Create components for local search\n",
    "context_selector = ContextSelector.build_default(\n",
    "    entities_vector_store=entities_vector_store,\n",
    "    entities_top_k=10,\n",
    "    community_level=cast(CommunityLevel, 2)\n",
    ")\n",
    "\n",
    "context_builder = ContextBuilder.build_default(\n",
    "    token_counter=TiktokenCounter(),\n",
    ")\n",
    "\n",
    "retriever = LocalSearchRetriever(\n",
    "    context_selector=context_selector,\n",
    "    context_builder=context_builder,\n",
    "    artifacts=artifacts,\n",
    ")\n",
    "\n",
    "local_search = LocalSearch(\n",
    "    prompt_builder=LocalSearchPromptBuilder(show_references=True),\n",
    "    llm=er_llm,\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "search_chain = local_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Search Example\n",
    "\n",
    "Demonstrate using the global search capability for broader questions about the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_graphrag.query.global_search import GlobalSearch\n",
    "from langchain_graphrag.query.global_search.community_weight_calculator import (\n",
    "    CommunityWeightCalculator\n",
    ")\n",
    "from langchain_graphrag.query.global_search.key_points_aggregator import (\n",
    "    KeyPointsAggregator,\n",
    "    KeyPointsAggregatorPromptBuilder,\n",
    "    KeyPointsContextBuilder,\n",
    ")\n",
    "from langchain_graphrag.query.global_search.key_points_generator import (\n",
    "    CommunityReportContextBuilder,\n",
    "    KeyPointsGenerator,\n",
    "    KeyPointsGeneratorPromptBuilder,\n",
    ")\n",
    "\n",
    "# Create components for global search\n",
    "report_context_builder = CommunityReportContextBuilder(\n",
    "    community_level=cast(CommunityLevel, 2),\n",
    "    weight_calculator=CommunityWeightCalculator(),\n",
    "    artifacts=artifacts,\n",
    "    token_counter=TiktokenCounter(),\n",
    ")\n",
    "\n",
    "kp_generator = KeyPointsGenerator(\n",
    "    llm=er_llm,\n",
    "    prompt_builder=KeyPointsGeneratorPromptBuilder(show_references=True),\n",
    "    context_builder=report_context_builder,\n",
    ")\n",
    "\n",
    "kp_aggregator = KeyPointsAggregator(\n",
    "    llm=er_llm,\n",
    "    prompt_builder=KeyPointsAggregatorPromptBuilder(show_references=True),\n",
    "    context_builder=KeyPointsContextBuilder(\n",
    "        token_counter=TiktokenCounter(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "global_search = GlobalSearch(\n",
    "    kp_generator=kp_generator,\n",
    "    kp_aggregator=kp_aggregator\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
