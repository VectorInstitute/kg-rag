{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC 10-Q Knowledge Graph Construction\n",
    "\n",
    "This notebook demonstrates constructing a knowledge graph from SEC 10-Q filings using LangChain. The approach uses LLM-based extraction to identify entities and relationships without pre-defining a schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install --quiet langchain langchain-neo4j langchain-openai neo4j python-dotenv networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import neo4j\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Initialize OpenAI client\n",
    "llm = ChatOpenAI(temperature=0, \n",
    "                 model_name=\"gpt-4o\", \n",
    "                 api_key=\"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\")\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "# Initialize empty list to store all documents\n",
    "documents = []\n",
    "\n",
    "# Get the docs directory path\n",
    "docs_path = \"../../data/sec-10-q/docs\"\n",
    "\n",
    "# Loop through all files in the docs directory\n",
    "for filename in os.listdir(docs_path):\n",
    "    # Check if the file is an AAPL PDF\n",
    "    if filename.endswith(\"AAPL.pdf\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(docs_path, filename)\n",
    "        \n",
    "        # Load and process the PDF\n",
    "        try:\n",
    "            raw_documents = PyPDFLoader(file_path=file_path).load()\n",
    "            \n",
    "            # Split the documents\n",
    "            text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "            split_documents = text_splitter.split_documents(raw_documents)\n",
    "            \n",
    "            # Filter metadata\n",
    "            processed_documents = filter_complex_metadata(split_documents)\n",
    "            \n",
    "            # Append to our collection\n",
    "            documents.extend(processed_documents)\n",
    "            \n",
    "            print(f\"Processed: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "# Now all_documents contains the processed documents from all AAPL PDFs\n",
    "print(f\"Total documents processed: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(tqdm(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph_documents\n",
    "import pickle\n",
    "\n",
    "with open(\"graph_documents_appl.pkl\", \"wb\") as f:\n",
    "    pickle.dump(graph_documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph_documents\n",
    "import pickle\n",
    "\n",
    "with open(\"graph_documents_appl.pkl\", \"rb\") as f:\n",
    "    graph_documents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph\n",
    "\n",
    "graph = NetworkxEntityGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for doc in graph_documents:\n",
    "    for node in doc.nodes:\n",
    "        graph.add_node(node.id)\n",
    "\n",
    "for doc in graph_documents:\n",
    "    for edge in doc.relationships:\n",
    "        graph._graph.add_edge(\n",
    "            edge.source.id,\n",
    "            edge.target.id,\n",
    "            relation=edge.type,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_triples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph\n",
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(graph._graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge graph has been constructed and stored in Neo4j. You can now query it using Cypher or use it for downstream tasks like question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphQAChain\n",
    "\n",
    "graph_chain = GraphQAChain.from_llm(\n",
    "    llm=llm, \n",
    "    graph=graph, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\"Where was Apple Inc. Incorporated?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\" On April 1, 2023, what was the Amount of CASH_BEGINNING_BALANCE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\"What assets does Apple Inc. have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\"Apple inc. What was the amount for Cash Used In Investing Activities in 2023 Q3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\"What was Apple Inc's Products gross margin percentage for the third quarter of 2022? Provide the percentage rounded to one decimal place.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"../../data/sec-10-q/synthetic_qna_data_7_gpt4o.csv\")\n",
    "\n",
    "# Filter for rows where Source Docs contains only AAPL\n",
    "apple_df = df[df['Source Docs'].str.contains('AAPL', na=False)]\n",
    "\n",
    "# Take first 10 samples\n",
    "apple_df = apple_df.head(10)\n",
    "\n",
    "# Evaluate the model\n",
    "correct = 0\n",
    "for i, row in apple_df.iterrows():\n",
    "    question = row[\"New Question\"]\n",
    "    answer = row[\"New Answer\"]\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(f\"Expected Answer: {answer}\")\n",
    "    response = graph_chain.invoke(input=question)\n",
    "    print(f\"Model Response: {response}\")\n",
    "    if response == answer:\n",
    "        correct += 1\n",
    "        \n",
    "print(f\"\\nAccuracy: {correct / 10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
