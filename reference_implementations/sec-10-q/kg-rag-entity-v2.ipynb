{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC 10-Q Knowledge Graph Construction\n",
    "\n",
    "This notebook demonstrates constructing a knowledge graph from SEC 10-Q filings using LangChain. The approach uses LLM-based extraction to identify entities and relationships without pre-defining a schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import neo4j\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "llm = ChatOpenAI(temperature=0, \n",
    "                 model_name=\"gpt-4o\", \n",
    "                 api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Check if \"graph_documents.pkl\" exists\n",
    "if os.path.exists(\"graph_documents.pkl\"):\n",
    "    # Load graph_documents from the file\n",
    "    with open(\"graph_documents.pkl\", \"rb\") as f:\n",
    "        graph_documents = pickle.load(f)\n",
    "    print(\"Loaded graph_documents from graph_documents.pkl\")\n",
    "else:\n",
    "    # Convert documents to graph documents\n",
    "    graph_documents = llm_transformer.convert_to_graph_documents(tqdm(documents))\n",
    "    \n",
    "    # Save graph_documents to the file\n",
    "    with open(\"graph_documents.pkl\", \"wb\") as f:\n",
    "        pickle.dump(graph_documents, f)\n",
    "    print(\"Converted documents to graph_documents and saved to graph_documents.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph\n",
    "\n",
    "graph = NetworkxEntityGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for doc in graph_documents:\n",
    "    for node in doc.nodes:\n",
    "        graph.add_node(node.id)\n",
    "\n",
    "for doc in graph_documents:\n",
    "    for edge in doc.relationships:\n",
    "        graph._graph.add_edge(\n",
    "            edge.source.id,\n",
    "            edge.target.id,\n",
    "            relation=edge.type,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the depth to go down\n",
    "n_hops = 5\n",
    "\n",
    "# Select a random node from the graph\n",
    "random_node = \"Apple Inc.\"\n",
    "\n",
    "# Function to recursively add a random neighbor up to n_hops\n",
    "def add_neighbors(node, depth, nodes_to_include):\n",
    "    if depth > 0:\n",
    "        neighbors = list(graph._graph.neighbors(node))\n",
    "        if neighbors:\n",
    "            random_neighbor = random.choice(neighbors)\n",
    "            nodes_to_include.add(random_neighbor)\n",
    "            add_neighbors(random_neighbor, depth - 1, nodes_to_include)\n",
    "\n",
    "# Create 16 subplots\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(16):\n",
    "    # Initialize the list of nodes to include in the subgraph\n",
    "    nodes_to_include = {random_node}\n",
    "    \n",
    "    # Add neighbors starting from the random node\n",
    "    add_neighbors(random_node, n_hops, nodes_to_include)\n",
    "    \n",
    "    # Extract the subgraph containing the selected nodes\n",
    "    subgraph = graph._graph.subgraph(nodes_to_include)\n",
    "    \n",
    "    # Draw the subgraph\n",
    "    pos = nx.spring_layout(subgraph)\n",
    "    nx.draw(subgraph, pos, with_labels=True, node_size=2000, node_color=\"skyblue\", font_size=10, font_weight=\"bold\", ax=axes[i])\n",
    "    edge_labels = nx.get_edge_attributes(subgraph, 'relation')\n",
    "    nx.draw_networkx_edge_labels(subgraph, pos, edge_labels=edge_labels, font_color='red', ax=axes[i])\n",
    "    axes[i].set_title(f\"Subgraph {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge graph has been constructed and stored in Neo4j. You can now query it using Cypher or use it for downstream tasks like question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "class EntityLinker:\n",
    "    def __init__(self, graph):\n",
    "        self.node_ids = list(graph._graph.nodes())\n",
    "        self.embeddings_model = OpenAIEmbeddings()\n",
    "        self.node_embeddings = self.embeddings_model.embed_documents(self.node_ids)\n",
    "    \n",
    "    def link_entities(self, query, top_n=3):\n",
    "        # Extract entities using LLM\n",
    "        entity_prompt = f\"\"\"Extract key entities from this query: {query}\n",
    "        Return as comma-separated list:\"\"\"\n",
    "        entities = llm.invoke(entity_prompt).content.split(',')\n",
    "        \n",
    "        # Find closest nodes for each entity\n",
    "        matched_nodes = []\n",
    "        for entity in entities:\n",
    "            query_embed = self.embeddings_model.embed_query(entity.strip())\n",
    "            similarities = [1 - cosine(query_embed, node_embed) for node_embed in self.node_embeddings]\n",
    "            top_indices = np.argsort(similarities)[-top_n:]\n",
    "            matched_nodes.extend([self.node_ids[i] for i in top_indices])\n",
    "        \n",
    "        return list(set(matched_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import random\n",
    "\n",
    "def expand_subgraph(graph, seed_nodes, depth=2):\n",
    "    \"\"\"\n",
    "    Expand subgraph from seed nodes while preserving edge attributes\n",
    "    \"\"\"\n",
    "    subgraph = nx.DiGraph()\n",
    "    nodes_to_explore = set(seed_nodes)\n",
    "    explored = set()\n",
    "    \n",
    "    for _ in range(depth):\n",
    "        current_level = nodes_to_explore - explored\n",
    "        if not current_level:\n",
    "            break\n",
    "            \n",
    "        for node in current_level:\n",
    "            if node in graph:\n",
    "                # Add outgoing edges\n",
    "                for _, target, data in graph.edges(node, data=True):\n",
    "                    subgraph.add_edge(node, target, **data)\n",
    "                \n",
    "                # Add incoming edges\n",
    "                for source, _, data in graph.in_edges(node, data=True):\n",
    "                    subgraph.add_edge(source, node, **data)\n",
    "                \n",
    "                # Add neighbors to exploration set\n",
    "                nodes_to_explore.update(graph.successors(node))\n",
    "                nodes_to_explore.update(graph.predecessors(node))\n",
    "        \n",
    "        explored.update(current_level)\n",
    "    \n",
    "    return subgraph\n",
    "\n",
    "class GraphQAChain:\n",
    "    def __init__(self, llm, nx_graph, entity_linker, verbose=True):\n",
    "        self.llm = llm\n",
    "        self.nx_graph = nx_graph\n",
    "        self.entity_linker = entity_linker\n",
    "        self.verbose = verbose\n",
    "        self.qa_prompt = PromptTemplate(\n",
    "            template=\"\"\"Based on the following knowledge graph triplets:\n",
    "            {triplets}\n",
    "            \n",
    "            Please answer this question: {question}\n",
    "            \n",
    "            If you cannot find the exact information in the triplets, say \"I cannot find the specific information in the available data.\"\n",
    "            \"\"\",\n",
    "            input_variables=[\"triplets\", \"question\"]\n",
    "        )\n",
    "\n",
    "    def _print_verbose(self, msg, data=None):\n",
    "        \"\"\"Helper method for verbose output with optional data\"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(msg)\n",
    "            if data:\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        print(f\"  ‚Ä¢ {item}\")\n",
    "                else:\n",
    "                    print(data)\n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    def invoke(self, query):\n",
    "        # Step 1: Entity linking\n",
    "        seed_nodes = self.entity_linker.link_entities(query)\n",
    "        if self.verbose:\n",
    "            self._print_verbose(\"üîç Detected Entities:\", seed_nodes)\n",
    "        \n",
    "        # Step 2: Subgraph expansion\n",
    "        subgraph = expand_subgraph(self.nx_graph, seed_nodes)\n",
    "        \n",
    "        # Step 3: Triplet extraction and formatting\n",
    "        try:\n",
    "            triplets = [\n",
    "                f\"{u} ‚Üí {data.get('relation', 'RELATED_TO')} ‚Üí {v}\"\n",
    "                for u, v, data in subgraph.edges(data=True)\n",
    "            ]\n",
    "            \n",
    "            if not triplets:\n",
    "                self._print_verbose(\"‚ö†Ô∏è No relevant triplets found in knowledge graph\")\n",
    "                return self.llm.invoke(\"I cannot find any relevant connections in the knowledge graph to answer this question.\")\n",
    "            \n",
    "            # If there are many triplets, show a sample in verbose mode\n",
    "            if self.verbose:\n",
    "                sample_size = min(5, len(triplets))\n",
    "                sample_triplets = random.sample(triplets, sample_size)\n",
    "                self._print_verbose(\n",
    "                    f\"üìä Found {len(triplets)} relevant connections. Sample of {sample_size}:\", \n",
    "                    sample_triplets\n",
    "                )\n",
    "            \n",
    "            # Step 4: LLM reasoning\n",
    "            response = self.llm.invoke(self.qa_prompt.format(\n",
    "                triplets=\"\\n\".join(triplets),\n",
    "                question=query\n",
    "            ))\n",
    "            \n",
    "            if self.verbose:\n",
    "                self._print_verbose(\"ü§î Final Answer:\", response.content)\n",
    "            \n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing graph: {str(e)}\"\n",
    "            self._print_verbose(\"‚ùå Error:\", error_msg)\n",
    "            return self.llm.invoke(\"There was an error processing the knowledge graph structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize linker component\n",
    "entity_linker = EntityLinker(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_chain = GraphQAChain(llm, graph._graph, entity_linker)\n",
    "\n",
    "# Sample usage\n",
    "response = enhanced_chain.invoke(\n",
    "    \"What was Apple Inc's Products gross margin percentage for the third quarter of 2022? Provide the percentage rounded to one decimal place.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_chain.invoke(invoke(input=\"Where was Apple Inc. Incorporated?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\" On April 1, 2023, what was the Amount of CASH_BEGINNING_BALANCE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\"What assets does Apple Inc. have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\"Apple inc. What was the amount for Cash Used In Investing Activities in 2023 Q3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain.invoke(input=\"What was Apple Inc's Products gross margin percentage for the third quarter of 2022? Provide the percentage rounded to one decimal place.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"../../data/sec-10-q/synthetic_qna_data_7_gpt4o.csv\")\n",
    "\n",
    "# Filter for rows where Source Docs contains only AAPL\n",
    "apple_df = df[df['Source Docs'].str.contains('AAPL', na=False)]\n",
    "\n",
    "# Take first 10 samples\n",
    "apple_df = apple_df.head(10)\n",
    "\n",
    "# Evaluate the model\n",
    "correct = 0\n",
    "for i, row in apple_df.iterrows():\n",
    "    question = row[\"New Question\"]\n",
    "    answer = row[\"New Answer\"]\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(f\"Expected Answer: {answer}\")\n",
    "    response = graph_chain.invoke(input=question)\n",
    "    print(f\"Model Response: {response}\")\n",
    "    if response == answer:\n",
    "        correct += 1\n",
    "        \n",
    "print(f\"\\nAccuracy: {correct / 10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
